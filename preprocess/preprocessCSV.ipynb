{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579c0c17",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db428835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "import json \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map country code to country name\n",
    "country_name = pycountry.countries.get(alpha_2='AG').name\n",
    "country_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48311f80",
   "metadata": {},
   "source": [
    "# Add row number to each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name(path, dictionary):\n",
    "    for each in dictionary.items():\n",
    "        name = pycountry.countries.get(alpha_2=each[0]).name\n",
    "        old_name = path + name + '.csv'\n",
    "        new_name = path + str(each[1]) + '_' + name + '.csv'\n",
    "        os.rename(old_name, new_name)\n",
    "\n",
    "def write_json(file_name, dictionary):\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        json.dump(dictionary, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de396e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05815a08",
   "metadata": {},
   "source": [
    "# Early: Kaggle 2020 1~8\n",
    "- Kaggle 3&4: https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-early-april\n",
    "- Kaggle 7&8:   Miss URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_files_03 = ['2020-03-29.csv', '2020-03-30.csv', '2020-03-31.csv', '2020-04-01.csv', '2020-04-02.csv',\n",
    "                  '2020-04-03.csv', '2020-04-04.csv', '2020-04-05.csv', '2020-04-06.csv', '2020-04-07.csv',\n",
    "                  '2020-04-08.csv', '2020-04-09.csv', '2020-04-10.csv', '2020-04-11.csv', '2020-04-12.csv',\n",
    "                  '2020-04-13.csv', '2020-04-14.csv', '2020-04-15.csv']\n",
    "\n",
    "early_file_07 = '2020-07.csv'\n",
    "\n",
    "\n",
    "early_original_path = 'Data/Early/'            # The path stores the original data\n",
    "early_processed_path = 'Data/Early_Processed/' # The path stores the processed data\n",
    "\n",
    "early_num = {}                          # key is country_code, value is number of row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e04020",
   "metadata": {},
   "source": [
    "### Kaggle 3 & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_early_3_file(original_path, processed_path, files):\n",
    "    for i, file_name in enumerate(files):\n",
    "        file = pd.read_csv(original_path + file_name, index_col=False, error_bad_lines=False, engine='python')\n",
    "\n",
    "        # Drop some useless columns\n",
    "        file = file.drop(columns=['status_id', 'reply_to_status_id', 'reply_to_user_id', 'reply_to_screen_name',\n",
    "                                  'is_quote', 'place_type', 'retweet_count'])\n",
    "        \n",
    "        # Remove the row where the value of 'country_code' is NaN, and the value of 'lang' is not 'en'\n",
    "        file = file.dropna(subset=['country_code'])\n",
    "        file = file.drop(file[file.lang != 'en'].index)\n",
    "        \n",
    "        file = file.drop(columns=['lang'])\n",
    "\n",
    "        file.rename(columns={\"place_full_name\": \"country_name\"}, inplace=True)\n",
    "        \n",
    "        file.rename(columns={\"screen_name\": \"user_name\"}, inplace=True)\n",
    "        file.rename(columns={\"source\": \"user_source\"}, inplace=True)\n",
    "        file.rename(columns={\"account_created_at\": \"user_created_at\"}, inplace=True)\n",
    "        file.rename(columns={\"favourites_count\": \"user_favourites_count\"}, inplace=True)\n",
    "        file.rename(columns={\"followers_count\": \"user_followers_count\"}, inplace=True)\n",
    "        file.rename(columns={\"friends_count\": \"user_friends_count\"}, inplace=True)\n",
    "        file.rename(columns={\"verified\": \"user_verified\"}, inplace=True)\n",
    "\n",
    "        file.rename(columns={\"created_at\": \"tweet_created_at\"}, inplace=True)\n",
    "        file.rename(columns={\"is_retweet\": \"tweet_is_retweet\"}, inplace=True)\n",
    "        file.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "        \n",
    "        file['tweet_created_at'] = pd.to_datetime(file['tweet_created_at'])\n",
    "        file['user_created_at'] = pd.to_datetime(file['user_created_at'])\n",
    "        \n",
    "        file = file.reindex(columns=['tweet_created_at', 'country_code', 'country_name',\n",
    "                                 'user_id', 'user_created_at', 'user_name', 'user_source', 'user_verified',\n",
    "                                 'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                                 'tweet_is_retweet', 'tweet'])\n",
    "\n",
    "        # Sort each row by country_code\n",
    "        file = file.sort_values(by=['country_code'])\n",
    "\n",
    "        country_code = set(file['country_code'])\n",
    "\n",
    "        for country in country_code:\n",
    "            try:\n",
    "                # The output file name of csv\n",
    "                output_path = processed_path + pycountry.countries.get(alpha_2=country).name+'.csv'\n",
    "\n",
    "                temp = file.loc[file['country_code'] == country]\n",
    "\n",
    "                if country not in early_num:\n",
    "                    temp.to_csv(output_path, index=False)\n",
    "                else:\n",
    "                    temp.to_csv(output_path, mode='a', header=False, index=False)\n",
    "\n",
    "                # If the country_code in dictionary, increment num\n",
    "                # If not in dictionary, set 0, then increment num\n",
    "                early_num[country] = early_num.get(country, 0) + len(temp)\n",
    "\n",
    "            except:\n",
    "                print(\"In [\", file_name, \"] Can not recognize this country code:\", country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461309bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_early_3_file(early_original_path, early_processed_path, early_files_03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3f4c7",
   "metadata": {},
   "source": [
    "### Kaggle 7 & 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d33210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_early_7_file(original_path, processed_path, file_name):\n",
    "    file = pd.read_csv(original_path + file_name, index_col=False, error_bad_lines=False, engine='python')\n",
    "    # file = file.drop(columns=['user_location', 'user_description', 'hashtags'])\n",
    "\n",
    "    file.rename(columns={\"user_created\": \"user_created_at\"}, inplace=True)\n",
    "    file.rename(columns={\"user_favourites\": \"user_favourites_count\"}, inplace=True)\n",
    "    file.rename(columns={\"user_friends\": \"user_friends_count\"}, inplace=True)\n",
    "    file.rename(columns={\"user_followers\": \"user_followers_count\"}, inplace=True)\n",
    "    file.rename(columns={\"source\": \"user_source\"}, inplace=True)\n",
    "\n",
    "    file.rename(columns={\"date\": \"tweet_created_at\"}, inplace=True)\n",
    "    file.rename(columns={\"is_retweet\": \"tweet_is_retweet\"}, inplace=True)\n",
    "    file.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "\n",
    "    file['tweet_created_at'] = pd.to_datetime(file['tweet_created_at'])\n",
    "    \n",
    "    file = file.dropna(subset=['user_favourites_count'])\n",
    "    file = file.drop(file[file.user_favourites_count == 'None'].index)\n",
    "    file['user_favourites_count'] = file['user_favourites_count'].astype(int)\n",
    "\n",
    "    file = file.drop(file[file.user_created_at == 'False'].index)\n",
    "    file['user_created_at'] = pd.to_datetime(file['user_created_at'])\n",
    "    \n",
    "    file = file.dropna(subset=['country_code'])\n",
    "    file = file.drop(file[file.country_code == 'None'].index)\n",
    "\n",
    "    file = file.reindex(columns=['tweet_created_at', 'country_code', 'country_name',\n",
    "                                 'user_id', 'user_created_at', 'user_name', 'user_source', 'user_verified',\n",
    "                                 'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                                 'tweet_is_retweet', 'tweet'])\n",
    "\n",
    "    # Sort each row by country_code\n",
    "    file = file.sort_values(by=['country_code'])\n",
    "\n",
    "    country_code = set(file['country_code'])\n",
    "\n",
    "    for country in country_code:\n",
    "        try:\n",
    "            # The output file name of csv\n",
    "            output_path = processed_path + pycountry.countries.get(alpha_2=country).name+'.csv'\n",
    "\n",
    "            temp = file.loc[file['country_code'] == country]\n",
    "            \n",
    "            if country not in early_num:\n",
    "                temp.to_csv(output_path, index=False)\n",
    "            else:\n",
    "                temp.to_csv(output_path, mode='a', header=False, index=False)\n",
    "                \n",
    "            # If the country_code in dictionary, increment num\n",
    "            # If not in dictionary, set 0, then increment num\n",
    "            early_num[country] = early_num.get(country, 0) + len(temp)\n",
    "\n",
    "        except:\n",
    "            print(\"In [\", file_name, \"] Can not recognize this country code:\", country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a1e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_early_7_file(early_original_path, early_processed_path, early_file_07)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b04f9e",
   "metadata": {},
   "source": [
    "### Add row number to each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828adb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_name(early_processed_path, early_num)\n",
    "write_json(early_processed_path + \"early_country_num.json\", early_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb6fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4d6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "825798a5",
   "metadata": {},
   "source": [
    "# Mid: Kaggle 2020 9~2021 4\n",
    "\n",
    "- TA Code 11:   https://hkustconnect-my.sharepoint.com/personal/euhaq_connect_ust_hk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Feuhaq%5Fconnect%5Fust%5Fhk%2FDocuments%2FSNA%5Fdata%2FCOVID%5F&ga=1\n",
    "- TA Code 12:   https://hkustconnect-my.sharepoint.com/personal/euhaq_connect_ust_hk/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Feuhaq%5Fconnect%5Fust%5Fhk%2FDocuments%2FSNA%5Fdata%2Fcovid%2D11%2Ddec%2Dvaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_files = ['10039.csv', '10043.csv', '10044.csv', '10047.csv',\n",
    "                          '10383.csv','10385.csv', '10386.csv']\n",
    "\n",
    "mid_original_path = 'Data/Mid/'            # The path stores the original data\n",
    "mid_processed_path = 'Data/Mid_Processed/' # The path stores the processed data\n",
    "\n",
    "mid_num = {}                          # key is country_code, value is number of row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mid_11_file(original_path, processed_path, files):\n",
    "    for file_name in files:\n",
    "        user = pd.read_csv(original_path + 'user_' + file_name, index_col=False, error_bad_lines=False, engine='python')\n",
    "        user.rename(columns={\"screen_name\": \"user_name\"}, inplace=True)\n",
    "\n",
    "        tweet = pd.read_csv(original_path + 'tweet_' + file_name, index_col=False, error_bad_lines=False, engine='python')\n",
    "        tweet.rename(columns={\"user\": \"user_name\"}, inplace=True)\n",
    "\n",
    "        file = pd.merge(user, tweet, on=\"user_name\", how=\"outer\")\n",
    "\n",
    "        file.rename(columns={\"date\": \"tweet_created_at\"}, inplace=True)\n",
    "\n",
    "        file.rename(columns={\"id\": \"user_id\"}, inplace=True)\n",
    "        file.rename(columns={\"created_at\": \"user_created_at\"}, inplace=True)\n",
    "        file.rename(columns={\"followers_count\": \"user_followers_count\"}, inplace=True)\n",
    "        file.rename(columns={\"verified\": \"user_verified\"}, inplace=True)\n",
    "\n",
    "\n",
    "        file.rename(columns={\"is_retweet\": \"tweet_is_retweet\"}, inplace=True)\n",
    "        file.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "\n",
    "        file['user_followers_count'] = pd.to_numeric(file['user_followers_count'],errors='coerce')\n",
    "        file = file.dropna(subset=['user_followers_count'])\n",
    "        file['user_followers_count'] = file['user_followers_count'].astype(int)\n",
    "        \n",
    "        file = file.dropna(subset=['country_code'])\n",
    "\n",
    "        file = file.reindex(columns=['tweet_created_at', 'country_code', 'country_name',\n",
    "                                     'user_id', 'user_created_at', 'user_name', 'user_source', 'user_verified',\n",
    "                                     'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                                     'tweet_is_retweet', 'tweet'])\n",
    "\n",
    "        # Sort each row by country_code\n",
    "        file = file.sort_values(by=['country_code'])\n",
    "\n",
    "        country_code = set(file['country_code'])\n",
    "\n",
    "        for country in country_code:\n",
    "            try:\n",
    "                # The output file name of csv\n",
    "                output_path = processed_path + pycountry.countries.get(alpha_2=country).name+'.csv'\n",
    "\n",
    "                temp = file.loc[file['country_code'] == country]\n",
    "\n",
    "                if country not in mid_num:\n",
    "                    temp.to_csv(output_path, index=False)\n",
    "                else:\n",
    "                    temp.to_csv(output_path, mode='a', header=False, index=False)\n",
    "\n",
    "                # If the country_code in dictionary, increment num\n",
    "                # If not in dictionary, set 0, then increment num\n",
    "                mid_num[country] = mid_num.get(country, 0) + len(temp)\n",
    "\n",
    "            except:\n",
    "                print(\"In [\", file_name, \"] Can not recognize this country code:\", country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mid_11_file(mid_original_path, mid_processed_path, mid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_name(mid_processed_path, mid_num)\n",
    "write_json(mid_processed_path + \"mid_country_num.json\", mid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb82c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b3928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285fdee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b8f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7397236a",
   "metadata": {},
   "source": [
    "# Late: Kaggle 2021 5~12\n",
    "\n",
    "- Kaggle 11&12:   Miss URL\n",
    "- Kaggle 2&4:     Miss URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ad7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "late_file_11 = '2021-11 & 12.csv'\n",
    "late_file_02 = '2022-02 & 03.csv'\n",
    "\n",
    "\n",
    "late_original_path = 'Data/Late/'            # The path stores the original data\n",
    "late_processed_path = 'Data/Late_Processed/' # The path stores the processed data\n",
    "\n",
    "late_num = {}                          # key is country_code, value is number of row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177acfb3",
   "metadata": {},
   "source": [
    "### Kaggle 11 & 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5811f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_late_11_file(original_path, processed_path, file_name):\n",
    "    file = pd.read_csv(original_path + file_name, index_col=False, error_bad_lines=False, engine='python')\n",
    "    # file = file.drop(columns=['user_location', 'user_description', 'hashtags'])\n",
    "\n",
    "    file.rename(columns={\"user_created\": \"user_created_at\"}, inplace=True)\n",
    "    file.rename(columns={\"source\": \"user_source\"}, inplace=True)\n",
    "    file.rename(columns={\"user_favourites\": \"user_favourites_count\"}, inplace=True)\n",
    "    file.rename(columns={\"user_friends\": \"user_friends_count\"}, inplace=True)\n",
    "    file.rename(columns={\"user_followers\": \"user_followers_count\"}, inplace=True)\n",
    "\n",
    "    file.rename(columns={\"date\": \"tweet_created_at\"}, inplace=True)\n",
    "    file.rename(columns={\"is_retweet\": \"tweet_is_retweet\"}, inplace=True)\n",
    "    file.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "\n",
    "    file['user_followers_count'] = file['user_followers_count'].astype(int)\n",
    "\n",
    "\n",
    "    file['tweet_created_at'] = pd.to_datetime(file['tweet_created_at'])\n",
    "    # file = file.drop(file[file.user_created_at == 'False'].index)\n",
    "    file['user_created_at'] = pd.to_datetime(file['user_created_at'])\n",
    "\n",
    "    file = file.reindex(columns=['tweet_created_at', 'country_code', 'country_name',\n",
    "                                 'user_id', 'user_created_at', 'user_name', 'user_source', 'user_verified',\n",
    "                                 'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                                 'tweet_is_retweet', 'tweet'])\n",
    "\n",
    "    # Sort each row by country_code\n",
    "    file = file.sort_values(by=['country_code'])\n",
    "\n",
    "    country_code = set(file['country_code'])\n",
    "\n",
    "    for country in country_code:\n",
    "        try:\n",
    "            # The output file name of csv\n",
    "            output_path = processed_path + pycountry.countries.get(alpha_2=country).name+'.csv'\n",
    "\n",
    "            temp = file.loc[file['country_code'] == country]\n",
    "\n",
    "            if country not in late_num:\n",
    "                temp.to_csv(output_path, index=False)\n",
    "            else:\n",
    "                temp.to_csv(output_path, mode='a', header=False, index=False)\n",
    "\n",
    "            # If the country_code in dictionary, increment num\n",
    "            # If not in dictionary, set 0, then increment num\n",
    "            late_num[country] = late_num.get(country, 0) + len(temp)\n",
    "\n",
    "        except:\n",
    "            print(\"In [\", file_name, \"] Can not recognize this country code:\", country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a03bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_late_11_file(late_original_path, late_processed_path, late_file_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8726e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_late_02_file(original_path, processed_path, file_name):\n",
    "    file = pd.read_csv(\"Data/Late/2022-02 & 03.csv\", index_col=False, error_bad_lines=False, engine='python')\n",
    "    # file = file.drop(columns=['user_location', 'user_description', 'hashtags'])\n",
    "\n",
    "    file.rename(columns={\"user_created\": \"user_created_at\"}, inplace=True)\n",
    "    file.rename(columns={\"id\": \"user_id\"}, inplace=True)\n",
    "    file.rename(columns={\"source\": \"user_source\"}, inplace=True)\n",
    "    file.rename(columns={\"user_favourites\": \"user_favourites_count\"}, inplace=True)\n",
    "    file.rename(columns={\"user_friends\": \"user_friends_count\"}, inplace=True)\n",
    "    file.rename(columns={\"user_followers\": \"user_followers_count\"}, inplace=True)\n",
    "\n",
    "\n",
    "    file.rename(columns={\"date\": \"tweet_created_at\"}, inplace=True)\n",
    "    file.rename(columns={\"is_retweet\": \"tweet_is_retweet\"}, inplace=True)\n",
    "    file.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "\n",
    "\n",
    "    file = file.dropna(subset=['country_code'])\n",
    "    file['tweet_created_at'] = pd.to_datetime(file['tweet_created_at'])\n",
    "    file = file.drop(file[file.user_created_at == '1'].index)\n",
    "    file['user_created_at'] = pd.to_datetime(file['user_created_at'])\n",
    "\n",
    "    file = file.reindex(columns=['tweet_created_at', 'country_code', 'country_name',\n",
    "                                 'user_id', 'user_created_at', 'user_name', 'user_source', 'user_verified',\n",
    "                                 'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                                 'tweet_is_retweet', 'tweet'])\n",
    "\n",
    "    # Sort each row by country_code\n",
    "    file = file.sort_values(by=['country_code'])\n",
    "\n",
    "    country_code = set(file['country_code'])\n",
    "\n",
    "    for country in country_code:\n",
    "        try:\n",
    "            # The output file name of csv\n",
    "            output_path = processed_path + pycountry.countries.get(alpha_2=country).name+'.csv'\n",
    "\n",
    "            temp = file.loc[file['country_code'] == country]\n",
    "\n",
    "            if country not in late_num:\n",
    "                temp.to_csv(output_path, index=False)\n",
    "            else:\n",
    "                temp.to_csv(output_path, mode='a', header=False, index=False)\n",
    "\n",
    "            # If the country_code in dictionary, increment num\n",
    "            # If not in dictionary, set 0, then increment num\n",
    "            late_num[country] = late_num.get(country, 0) + len(temp)\n",
    "\n",
    "        except:\n",
    "            print(\"In [\", file_name, \"] Can not recognize this country code:\", country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebcf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_late_02_file(late_original_path, late_processed_path, late_file_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c0306",
   "metadata": {},
   "source": [
    "### Add row number to each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9440b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_name(late_processed_path, late_num)\n",
    "write_json(late_processed_path + \"late_country_num.json\", late_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753527f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce72dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7c627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b23e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70ffda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba7177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7b5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859eede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f99a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da115c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0a5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2178c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7368b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217362e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ae369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"Data/Late/2022-02 & 03.csv\", index_col=False, error_bad_lines=False, engine='python')\n",
    "# file = file.drop(columns=['user_location', 'user_description', 'hashtags'])\n",
    "\n",
    "file.rename(columns={\"user_created\": \"user_created_at\"}, inplace=True)\n",
    "file.rename(columns={\"id\": \"user_id\"}, inplace=True)\n",
    "file.rename(columns={\"source\": \"user_source\"}, inplace=True)\n",
    "file.rename(columns={\"user_favourites\": \"user_favourites_count\"}, inplace=True)\n",
    "file.rename(columns={\"user_friends\": \"user_friends_count\"}, inplace=True)\n",
    "file.rename(columns={\"user_followers\": \"user_followers_count\"}, inplace=True)\n",
    "\n",
    "\n",
    "file.rename(columns={\"date\": \"tweet_created_at\"}, inplace=True)\n",
    "file.rename(columns={\"is_retweet\": \"tweet_is_retweet\"}, inplace=True)\n",
    "file.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "file['tweet_created_at'] = pd.to_datetime(file['tweet_created_at'])\n",
    "file = file.drop(file[file.user_created_at == '1'].index)\n",
    "file['user_created_at'] = pd.to_datetime(file['user_created_at'])\n",
    "\n",
    "file = file.reindex(columns=['tweet_created_at', 'country_code', 'country_name',\n",
    "                             'user_id', 'user_created_at', 'user_name', 'user_source', 'user_verified',\n",
    "                             'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                             'tweet_is_retweet', 'tweet'])\n",
    " \n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv(\"Data/Late/2022-02 & 03.csv\", index_col=False, error_bad_lines=False, engine='python')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f905308",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for each in b['user_created']:\n",
    "        pd.to_datetime(each)\n",
    "except:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23dca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"Data/Mid/user_10039.csv\", index_col=False, error_bad_lines=False, engine='python')\n",
    "a.rename(columns={\"screen_name\": \"user_name\"}, inplace=True)\n",
    "b = pd.read_csv(\"Data/Mid/tweet_10039.csv\", index_col=False, error_bad_lines=False, engine='python')\n",
    "b.rename(columns={\"user\": \"user_name\"}, inplace=True)\n",
    "a = pd.merge(a, b, on=\"user_name\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a.rename(columns={\"date\": \"tweet_created_at\"}, inplace=True)\n",
    "\n",
    "a.rename(columns={\"id\": \"user_id\"}, inplace=True)\n",
    "a.rename(columns={\"created_at\": \"user_created_at\"}, inplace=True)\n",
    "a.rename(columns={\"followers_count\": \"user_followers_count\"}, inplace=True)\n",
    "a.rename(columns={\"verified\": \"user_verified\"}, inplace=True)\n",
    "\n",
    "\n",
    "a.rename(columns={\"is_retweet\": \"tweet_is_retweet\"}, inplace=True)\n",
    "a.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "\n",
    "a['user_followers_count'] = pd.to_numeric(a['user_followers_count'],errors='coerce')\n",
    "a.dropna(subset=['user_followers_count'], inplace= True)\n",
    "# try:\n",
    "#     for each in a['user_followers_count']:\n",
    "#         each.astype(int)\n",
    "# except:\n",
    "#     print(each)\n",
    "    \n",
    "a['user_followers_count'] = a['user_followers_count'].astype(int)\n",
    "\n",
    "a = a.dropna(subset=['country_code'])\n",
    "\n",
    "\n",
    "\n",
    "a = a.reindex(columns=['tweet_created_at', 'country_code', 'country_name',\n",
    "                                 'user_id', 'user_created_at', 'user_name', 'user_source', 'user_verified',\n",
    "                                 'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                                 'tweet_is_retweet', 'tweet'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7558092",
   "metadata": {},
   "outputs": [],
   "source": [
    "a['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f76cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/Mid/user_10039.csv\", index_col=False, engine='python')\n",
    "df['followers_count'] = pd.to_numeric(df['followers_count'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.drop(c[c['followers_count'].apply(lambda x: isinstance(x, int))])\n",
    "c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3913686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['followers_count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2b540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
