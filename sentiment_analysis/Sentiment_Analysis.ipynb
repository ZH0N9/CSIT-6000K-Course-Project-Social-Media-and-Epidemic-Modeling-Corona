{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirement\n",
    "\n",
    "# pip install -U textblob\n",
    "# pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SentimentIntensityAnalyzer class\n",
    "# from vaderSentiment.vaderSentiment module.\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word cloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "def create_wordcloud(text,name):\n",
    "    mask = np.array(Image.open(\"sentiment_analysis/cloud.png\"))\n",
    "\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.add('s')\n",
    "    stopwords.add('S')\n",
    "    wc = WordCloud(background_color=\"white\",\n",
    "    mask = mask,\n",
    "    random_state=40,\n",
    "    max_font_size=150,\n",
    "    max_words=2500,\n",
    "    stopwords=stopwords,\n",
    "    repeat=True)\n",
    "    wc.generate(str(text))\n",
    "    wc.to_file(name+\".png\")\n",
    "    print(\"Word Cloud Saved Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text\n",
    "def clean_text(content):\n",
    "\t# remove @.\n",
    "\tcontent = re.sub(r\"@\\w+\",\"\",str(content))\n",
    "\t# remove links\n",
    "\tcontent = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", str(content)) \n",
    "\t# remove hashtag sign \n",
    "\tcontent = str(content).replace(\"#\", \"\").replace(\"_\", \" \") \n",
    "\t# remove \\n\\t..\n",
    "\tcontent = re.sub(r\"\\r?\\n|\\r\",\"\",str(content))\n",
    "\treturn content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textblob\n",
    "def sentiment_scores_txtblob(file):\n",
    "    # create TextBlob object of passed tweet text\n",
    "    for index,tweet in file['tweet_clean'].iteritems():\n",
    "        tweet = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\"\",tweet)\n",
    "        analysis = TextBlob(tweet)\n",
    "        #file.loc[index,'polarity'] = analysis.sentiment.polarity\n",
    "        #file.loc[index,'subjectivity'] = analysis.sentiment.subjectivity\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            file.loc[index,'sentiment_txtblob']= 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            file.loc[index,'sentiment_txtblob']= 'neutral'\n",
    "        else:\n",
    "            file.loc[index,'sentiment_txtblob']= 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VADER\n",
    "\n",
    "def sentiment_scores_vader(file):\n",
    "\tfor index,tweet in file['tweet'].iteritems():\n",
    "\t\t# Create a SentimentIntensityAnalyzer object.\n",
    "\t\tsid_obj = SentimentIntensityAnalyzer()\n",
    "\t\t\n",
    "\t\t# polarity_scores method of SentimentIntensityAnalyzer\n",
    "\t\t# object gives a sentiment dictionary.\n",
    "\t\t# which contains pos, neg, neu, and compound scores.\n",
    "\t\tsentiment_dict = sid_obj.polarity_scores(tweet)\n",
    "\t\t'''\n",
    "\t\tprint(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "\t\tprint(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
    "\t\tprint(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
    "\t\tprint(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
    "\t\tprint(\"Sentence Overall Rated As\", end = \" \")\n",
    "\t\t'''\n",
    "\t\tfile.loc[index,'neg'] = sentiment_dict['neg']\n",
    "\t\tfile.loc[index,'neu'] = sentiment_dict['neu']\n",
    "\t\tfile.loc[index,'pos'] = sentiment_dict['pos']\n",
    "\t\tfile.loc[index,'comp'] = sentiment_dict['compound']\n",
    "\n",
    "\t\t# decide sentiment as positive, negative and neutral\n",
    "\t\tif sentiment_dict['compound'] >= 0.05 :\n",
    "\t\t\tfile.loc[index,'sentiment_vader']= 'positive'\n",
    "\n",
    "\t\telif sentiment_dict['compound'] <= - 0.05 :\n",
    "\t\t\tfile.loc[index,'sentiment_vader']= 'negative'\n",
    "\n",
    "\t\telse :\n",
    "\t\t\tfile.loc[index,'sentiment_vader']= 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename need to be changed\n",
    "# filename = data.csv''\n",
    "# e.g: filename='early/US.csv'\n",
    "\n",
    "filename = \"/Users/xihuang/Desktop/SocialNetwork-TeamProject/data/top10_country/early/873_Colombia.csv\"\n",
    "file = pd.read_csv(filename,index_col=False, error_bad_lines=False, engine='python',encoding=\"utf-8\")\n",
    "file = file.drop(columns=['user_id', 'user_created_at', 'user_name', 'user_source',\n",
    "                                  'user_verified', 'user_favourites_count', 'user_followers_count',\n",
    "                                  'user_friends_count','tweet_is_retweet'])\n",
    "file['tweet'] = list(map(lambda tweet:clean_text(tweet), list(file['tweet'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply vader sentiment\n",
    "sentiment_scores_vader(file)\n",
    "print(file)\n",
    "# extract pos,neg,neu tweets\n",
    "list_negative = file[file[\"sentiment_vader\"]==\"negative\"]\n",
    "list_positive = file[file[\"sentiment_vader\"]==\"positive\"]\n",
    "list_neutral = file[file[\"sentiment_vader\"]==\"neutral\"]\n",
    "#Creating wordcloud for all tweets\n",
    "create_wordcloud(list_positive['tweet'].values,\"pos\")\n",
    "create_wordcloud(list_neutral['tweet'].values,\"neu\")\n",
    "create_wordcloud(list_negative['tweet'].values,\"neg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "\n",
    "# count percentage for sentiment\n",
    "def count_values_in_column(data,feature):\n",
    " total=data.loc[:,feature].value_counts(dropna=False)\n",
    " percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    " return pd.concat([total,percentage],axis=1,keys=[\"Total\",\"Percentage\"])\n",
    "#Count_values for sentiment\n",
    "print(count_values_in_column(file,\"sentiment_vader\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bar by countries\n",
    "from pyecharts.charts import Bar\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.globals import ThemeType\n",
    "from pyecharts.render import make_snapshot\n",
    "\n",
    "def createSentiment(positive ,negative,neutral,name):\n",
    "    bar = (\n",
    "            Bar(init_opts=opts.InitOpts(width=\"1000px\",theme=ThemeType.INFOGRAPHIC))\n",
    "            .add_xaxis(['Early','Middle','Late'])\n",
    "            .add_yaxis(\"Position\",\n",
    "                positive\n",
    "                )\n",
    "            .add_yaxis(\"Negative\",\n",
    "               negative\n",
    "               )\n",
    "             .add_yaxis(\"Neutral\",\n",
    "                neutral\n",
    "                )\n",
    "            .set_series_opts(label_opts=opts.LabelOpts(\n",
    "                font_size=12,\n",
    "                font_weight=\"bold\",\n",
    "            ))\n",
    "            .set_global_opts(\n",
    "                legend_opts=opts.LegendOpts(\n",
    "                    pos_left='right',    # 图例放置的位置，分上下左右，可用左右中表示，也可用百分比表示\n",
    "                    pos_top='top',\n",
    "                    orient='vertical',   # horizontal、vertical #图例放置的方式 横着放or竖着放\n",
    "                    padding=30,\n",
    "                    textstyle_opts=opts.TextStyleOpts(\n",
    "                    font_size=12,\n",
    "                    font_weight='bold',\n",
    "                    color=\"#942c47\"\n",
    "                    \n",
    "                ),\n",
    "            ),\n",
    "            title_opts=opts.TitleOpts(\n",
    "                title=\"Sentiment Analysis(Percentage)\",\n",
    "                subtitle = \"Country:\"+name,\n",
    "                pos_left='center',\n",
    "                padding=20,\n",
    "                subtitle_textstyle_opts= opts.TextStyleOpts(\n",
    "                    color=\"#eb4c49\",\n",
    "                    font_weight='bold',\n",
    "                    font_size=15),\n",
    "                title_textstyle_opts= opts.TextStyleOpts(\n",
    "                    color=\"#942c47\",\n",
    "                    font_weight='bold',\n",
    "                    font_size=20)\n",
    "            ),\n",
    "            xaxis_opts=opts.AxisOpts(\n",
    "                axistick_opts=opts.AxisTickOpts(\n",
    "                    is_show=False, \n",
    "                ),\n",
    "                axislabel_opts=opts.LabelOpts(\n",
    "                    font_weight = \"bold\",\n",
    "                    font_size=12,\n",
    "                    color=\"#eb4c49\",\n",
    "                    rotate=30\n",
    "                )\n",
    "            ),\n",
    "            yaxis_opts=opts.AxisOpts(\n",
    "                axistick_opts=opts.AxisTickOpts(\n",
    "                    is_show=False, \n",
    "                ),\n",
    "                axislabel_opts=opts.LabelOpts(\n",
    "                    font_weight = \"bold\",\n",
    "                    font_size=12,\n",
    "                    color=\"#eb4c49\",\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            )\n",
    "        )\n",
    "    return bar\n",
    "bar_us = createSentiment([45.92,37.61,43.23],[28.35,31.37,31.05],[25.73,31.01,25.72],'United States')\n",
    "bar_us.render('sentiment_US.html')\n",
    "\n",
    "bar_uk = createSentiment([53.83,37.61,46.11],[50.61,39.13,32.73],[20.21,10.26,21.16],'United Kingdom')\n",
    "bar_uk.render('sentiment_UK.html')\n",
    "\n",
    "bar_th = createSentiment([35.11,49.49,37.41],[27.19,28.08,34.15],[37.71,22.42, 28.44],'Thailand')\n",
    "bar_th.render('sentiment_TH.html')\n",
    "\n",
    "bar_sa = createSentiment([43.7,40.41,42.38],[30.99,37.19,32.7],[25.31,22.68, 24.92],'South Africa')\n",
    "bar_sa.render('sentiment_SA.html')\n",
    "\n",
    "bar_sb = createSentiment([40.11,44.85,39.52],[ 39.16,34.96,35.38],[20.73,20.19, 25.11],'Serbia')\n",
    "bar_sb.render('sentiment_SB.html')\n",
    "\n",
    "bar_ng = createSentiment([49.41,44.75,43.09],[24.86,29.71,28.46],[25.73,25.54,28.46],'Nigeria')\n",
    "bar_ng.render('sentiment_NG.html')\n",
    "\n",
    "bar_ia = createSentiment([47.59,37.42,42.42],[29.11,37.00,34.03],[23.30, 25.58,23.54],'India')\n",
    "bar_ia.render('sentiment_Inda.html')\n",
    "\n",
    "bar_co = createSentiment([35.05,37.15,38.92],[35.17,34.39, 34.58],[29.78,28.46,26.50],'Colombia')\n",
    "bar_co.render('sentiment_Co.html')\n",
    "\n",
    "bar_ca = createSentiment([35.05,37.15,38.92],[35.17,34.39, 34.58],[29.78,28.46,26.50],'Canada')\n",
    "bar_ca.render('sentiment_Ca.html')\n",
    "\n",
    "bar_co = createSentiment([50.21,37.47,42.55],[25.41,32.47,31.03],[24.38,30.06,26.42],'Colombia')\n",
    "bar_co.render('sentiment_Co.html')\n",
    "\n",
    "bar_au = createSentiment([42.4,37.35,39.36],[29.55,33.96,35.28],[28.04,28.69,25.37],'Australia')\n",
    "bar_au.render('sentiment_Au.html')\n",
    "\n",
    "bar = createSentiment([45.93 ,34.53,40.78] ,[26.78,36.04,31.20] ,[27.29,29.43,28.02],'Overall')\n",
    "bar.render('sentiment.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heat map for each stage by countries\n",
    "from pyecharts.charts import Map\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "def createWordlMap(country_name,country_data):\n",
    "    country_list = [list(z) for z in zip(country_name,country_data)]\n",
    "    map = (Map(init_opts=opts.InitOpts(width = \"1200px\",height=\"800px\",theme=ThemeType.ESSOS))\n",
    "        .add(\n",
    "            \"COVID_Tweet_Map\",\n",
    "            country_list,\n",
    "            maptype=\"world\",\n",
    "            is_map_symbol_show=False,\n",
    "            itemstyle_opts=opts.ItemStyleOpts(\n",
    "                border_color=\"#fdfcf4\",\n",
    "\n",
    "            )\n",
    "        )\n",
    "        .set_series_opts(\n",
    "            label_opts=opts.LabelOpts(\n",
    "                is_show=False\n",
    "            ),\n",
    "        )\n",
    "        .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            title=\"The Overall Sentiment Average Score\",\n",
    "            pos_left='center',\n",
    "            padding=20,\n",
    "            item_gap = 10,\n",
    "            title_textstyle_opts= opts.TextStyleOpts(\n",
    "                font_weight='bold',\n",
    "                font_size=25),\n",
    "            subtitle_textstyle_opts= opts.TextStyleOpts(\n",
    "                font_weight='bold',\n",
    "                font_size=20),\n",
    "        ),\n",
    "        legend_opts=opts.LegendOpts(is_show=False),\n",
    "        visualmap_opts=opts.VisualMapOpts(\n",
    "            range_text=[\"High\", \"Low\"],\n",
    "            is_piecewise=True, \n",
    "            pieces =[\n",
    "                {\"min\": -0.09,\"max\":-0.05,\"label\":\"-0.09~-0.05\",'color':\"#3d707a\"},\n",
    "                {\"min\": -0.05, \"max\": -0.01,\"label\":\"-0.05~-0.01\",'color':\"#4c8c99\"},\n",
    "                {\"min\": -0.01, \"max\": 0.03,\"label\":\"-0.01~0.03\",'color':\"#69b8c7\"},\n",
    "                {\"min\": 0.03, \"max\": 0.07,\"label\":\"0.03~0.07\",'color':\"#f6dc7a\"},\n",
    "                {\"min\": 0.07, \"max\": 0.11,\"label\":\"0.07~0.11\",'color':\"#ecc641\"},\n",
    "                {\"min\": 0.11, \"max\": 0.15,\"label\":\"0.11~0.15\",'color':\"#e38931\"},\n",
    "                {\"min\": 0.15, \"max\": 0.19,\"label\":\"0.15~0.19\",'color':\"#e36331\"},\n",
    "                {\"min\": 0.19, \"max\": 0.23,\"label\":\"0.19~0.23\",'color':\"#e38931\"},\n",
    "                   \n",
    "            ],\n",
    "            pos_top= \"bottom\",  \n",
    "            pos_left=\"left\",\n",
    "            orient=\"vertical\",\n",
    "            textstyle_opts = opts.TextStyleOpts(\n",
    "                font_weight=\"bold\",\n",
    "                font_size=15\n",
    "            )\n",
    "        ))\n",
    "        )\n",
    "    return map\n",
    "with open('/Users/xihuang/Desktop/SocialNetwork-TeamProject/sentiment_analysis/result.json','r') as f:\n",
    "    country_data = json.load(f)\n",
    "\n",
    "country_name =list(country_data.keys())\n",
    "early_avg = list(map(lambda x:x['avg_list'][0],list(country_data.values())))\n",
    "middle_avg = list(map(lambda x:x['avg_list'][1],list(country_data.values())))\n",
    "late_avg = list(map(lambda x:x['avg_list'][2],list(country_data.values())))\n",
    "print(early_avg)\n",
    "print(middle_avg)\n",
    "print(late_avg)\n",
    "print(country_name)\n",
    "print(statistics.mean(early_avg))\n",
    "print(statistics.mean(middle_avg))\n",
    "print(statistics.mean(late_avg))\n",
    "\n",
    "print(statistics.stdev(early_avg))\n",
    "print(statistics.stdev(middle_avg))\n",
    "print(statistics.stdev(late_avg))\n",
    "\n",
    "#create world covid tweet volume map\n",
    "Early_map = createWordlMap(country_name,early_avg)\n",
    "Early_map.render('early_senti_Map.html')\n",
    "#create world covid tweet volume map\n",
    "Middle_map = createWordlMap(country_name,middle_avg)\n",
    "Middle_map.render('middle_senti_Map.html')\n",
    "#create world covid tweet volume map\n",
    "Late_map = createWordlMap(country_name,late_avg)\n",
    "Late_map.render('late_senti_Map.html')\n",
    "\n",
    "#create world covid tweet volume map\n",
    "#sentiment_map = createWordlMap(country_name,country_tweets)\n",
    "#sentiment_map.render('Map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pos,neg,neu sentiment score for different stage\n",
    "# path name need to be changed for different stages\n",
    "import os\n",
    "path = \"data/top10_country/early\" #文件夹目录\n",
    "files= os.listdir(path) #得到文件夹下的所有文件名称\n",
    "files = filter(lambda file:'.csv' in file,files)\n",
    "pos=0\n",
    "neg =0\n",
    "neu=0\n",
    "for file in files: \n",
    "    db = pd.read_csv(path+'/'+file,index_col=False, error_bad_lines=False, engine='python',encoding=\"utf-8\")\n",
    "    db = db.drop(columns=['user_id', 'user_created_at', 'user_name', 'user_source',\n",
    "                                  'user_verified', 'user_favourites_count', 'user_followers_count',\n",
    "                                  'user_friends_count','tweet_is_retweet'])\n",
    "    db['tweet'] = list(map(lambda tweet:clean_text(tweet), list(db['tweet'])))  \n",
    "    sentiment_scores_vader(db)\n",
    "    list_negative = db[db[\"sentiment_vader\"]==\"negative\"]\n",
    "    list_positive = db[db[\"sentiment_vader\"]==\"positive\"]\n",
    "    list_neutral = db[db[\"sentiment_vader\"]==\"neutral\"]\n",
    "    pos+=len(list_positive)\n",
    "    neg+=len(list_negative)\n",
    "    neu+=len(list_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average sentment score for countries\n",
    "# path name need to be changed for different countries\n",
    "import os\n",
    "# folder\n",
    "path = \"sentiment_analysis/sentiment_data\" \n",
    "folders= os.listdir(path) #get folders \n",
    "folders =list( filter(lambda folder:folder != '.DS_Store',folders))\n",
    "for folder in folders:\n",
    "    files= os.listdir(path+folder) #get files\n",
    "    files = list(filter(lambda file:'.csv' in file,files))\n",
    "    \n",
    "    avg = []\n",
    "    for file in files: \n",
    "        db = pd.read_csv(path+'/'+file,index_col=False, error_bad_lines=False, engine='python',encoding=\"utf-8\")\n",
    "        db = db.drop(columns=['user_id', 'user_created_at', 'user_name', 'user_source',\n",
    "                                    'user_verified', 'user_favourites_count', 'user_followers_count',\n",
    "                                    'user_friends_count','tweet_is_retweet'])\n",
    "        db['tweet'] = list(map(lambda tweet:clean_text(tweet), list(db['tweet'])))  \n",
    "        sentiment_scores_vader(db)\n",
    "        compoud_avg = db['comp'].mean()\n",
    "        avg.append(compoud_avg)\n",
    "    print(avg)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
